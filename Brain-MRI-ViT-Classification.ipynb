{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Brain MRI Binary Classificatin PyTorch ViT"
      ],
      "metadata": {
        "id": "RPGIfASwQcer"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg7SyP0CM2td"
      },
      "outputs": [],
      "source": [
        "# download dataset from\n",
        "!pip install --upgrade gdown\n",
        "!gdown --fuzzy 18RfTvv5NBKuUgMDJjxXb7BLYz31sT_aH --output brain.zip\n",
        "# unzip\n",
        "!unzip -q brain.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nF0BuAMYNEbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "class_map = {\n",
        "    'no': 0,\n",
        "    'yes': 1\n",
        "}\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "tkY674XzNNH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read single image\n",
        "img_paths = sorted(glob('./brain/*/*.jpg') + glob('./brain/*/*.JPG') + glob('./brain/*/*.jpeg'))"
      ],
      "metadata": {
        "id": "w20P6h_KNSlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of images\n",
        "len(img_paths)"
      ],
      "metadata": {
        "id": "wclZ0gz1NT0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show image\n",
        "path = img_paths[-9]\n",
        "img = Image.open(path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "print(path, img.size)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "N6KhMc6kNVES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract img class\n",
        "img_path = img_paths[-9]\n",
        "print(img_path)\n",
        "# read label\n",
        "cls = img_path.split('/')[-2]\n",
        "print(cls)\n",
        "# cls idx\n",
        "print(class_map[cls])"
      ],
      "metadata": {
        "id": "mNq69KfJNYxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset, Dataloader"
      ],
      "metadata": {
        "id": "J0Z8wglKODB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, paths, transform):\n",
        "        self.paths = paths\n",
        "        self.transform = transform\n",
        "        self.class_map = {\n",
        "            'no': 0,\n",
        "            'yes': 1\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "\n",
        "        cls = path.split('/')[-2]\n",
        "        label = self.class_map[cls]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "Kel5jU2qNwcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, val_paths = train_test_split(\n",
        "    img_paths,\n",
        "    test_size=0.3,\n",
        "    random_state=5566\n",
        ")\n",
        "len(train_paths), len(val_paths)"
      ],
      "metadata": {
        "id": "B-gKMC2fOxtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#遷移學習\n",
        "transforms = torchvision.models.ViT_B_16_Weights.DEFAULT.transforms()\n",
        "\n",
        "train_ds = BrainDataset(train_paths, transforms)\n",
        "val_ds = BrainDataset(val_paths, transforms)"
      ],
      "metadata": {
        "id": "MSOuAvWpPOw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transforms)"
      ],
      "metadata": {
        "id": "TQwclFnIBA1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_ds[0]\n",
        "img.shape, label"
      ],
      "metadata": {
        "id": "CwAHo3ggP43K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "img_raw = img.numpy().transpose(1, 2, 0) # (3, 256, 256) -> (256, 256, 3)\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "img_raw = std * img_raw + mean\n",
        "img_raw = np.clip(img_raw, 0, 1)\n",
        "print(img_raw.shape)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img_raw)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lhGEzcJA4UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, BS, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_ds, BS)"
      ],
      "metadata": {
        "id": "qlRDwWo_RSKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "hfRk1BAhQX4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.vit_b_16( #vit b 16\n",
        "    weights=torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        ")\n",
        "\n",
        "# freeze encoder\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "model.heads = nn.Sequential( #分類器\n",
        "    nn.Linear(in_features=768, out_features=2) #0 & 1\n",
        ")"
      ],
      "metadata": {
        "id": "w2C16INLP-rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 224, 224)\n",
        "outputs = model(inputs)\n",
        "outputs.shape"
      ],
      "metadata": {
        "id": "OJQZVJEBQhK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "IEfiZj2BQtHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "RyN4BX-RQrwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.train() # to training mode.\n",
        "    epoch_loss, epoch_correct = 0, 0\n",
        "    for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n",
        "        x, y = x.to(device), y.to(device) # move data to GPU\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute prediction loss\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Optimization by gradients\n",
        "        loss.backward() # backpropagation to compute gradients\n",
        "        optimizer.step() # update model params\n",
        "\n",
        "        # write to logs\n",
        "        epoch_loss += loss.item() # tensor -> python value\n",
        "        # (N, Class)\n",
        "        epoch_correct += (pred.argmax(dim=1) == y).sum().item()\n",
        "\n",
        "    # return avg loss of epoch, acc of epoch\n",
        "    return epoch_loss/num_batches, epoch_correct/size\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.eval() # model to test mode.\n",
        "    epoch_loss, epoch_correct = 0, 0\n",
        "\n",
        "    # No gradient for test data\n",
        "    with torch.no_grad():\n",
        "        for batch_i, (x, y) in enumerate(dataloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction loss\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            # write to logs\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "    return epoch_loss/num_batches, epoch_correct/size\n",
        "\n",
        "EPOCHS = 10\n",
        "logs = {\n",
        "    'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []\n",
        "}\n",
        "# Earlystopping\n",
        "patience = 5\n",
        "counter = 0\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_loss, train_acc = train(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss, val_acc = test(val_loader, model, loss_fn)\n",
        "\n",
        "    print(f'EPOCH: {epoch:04d} \\\n",
        "    train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} \\\n",
        "    val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f} ')\n",
        "\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['train_acc'].append(train_acc)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "    logs['val_acc'].append(val_acc)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), \"last.pth\")\n",
        "    # chcek improvement\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best.pth\")\n",
        "    else:\n",
        "        counter += 1\n",
        "    if counter >= patience:\n",
        "        print(\"Earlystop!\")\n",
        "        break"
      ],
      "metadata": {
        "id": "0yvEUkacQ7DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "20hH88JySCIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    recall_score, # sensitivity\n",
        "    precision_score,\n",
        "    f1_score,\n",
        "    roc_curve,\n",
        "    auc,\n",
        ")\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "eIeIqq15URl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best.pth'))\n",
        "_ = model.eval().to(device)"
      ],
      "metadata": {
        "id": "uKGTxgU9RP-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "y_pred = [] # predict class 最大值來看0 or 1\n",
        "y_pred_raw = [] # predict probabilities 紀錄機率值大小\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(val_loader):\n",
        "        x = x.to(device)\n",
        "        pred = model(x) # logits\n",
        "        pred = nn.functional.softmax(pred, dim=1) # apply softmax to logits\n",
        "        y_pred_raw.append(pred[:, 1]) # probability of class 1(有腫瘤的)\n",
        "        y_pred.append(pred.argmax(dim=1))\n",
        "        # threshold\n",
        "        # y_pred = [1 if p > threshold else 0 for p in y_pred_raw]\n",
        "\n",
        "        y_true.append(y)\n",
        "\n",
        "y_pred = torch.cat(y_pred, dim=0).cpu().numpy()\n",
        "y_pred_raw = torch.cat(y_pred_raw, dim=0).cpu().numpy()\n",
        "y_true = torch.cat(y_true, dim=0).cpu().numpy()"
      ],
      "metadata": {
        "id": "s3Ez4m22SZTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape, y_pred_raw.shape, y_true.shape"
      ],
      "metadata": {
        "id": "iTCA86yMTVnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:3], y_pred_raw[:3], y_true[:3]"
      ],
      "metadata": {
        "id": "15Xv_TCgTidL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification_report\n",
        "print(classification_report(y_true, y_pred,\n",
        "                            target_names=[\"NO\", \"YES\"],\n",
        "                            digits=3))"
      ],
      "metadata": {
        "id": "pWnQ_463T_3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sensitivity:\", recall_score(y_true, y_pred))\n",
        "print(\"Precision:  \", precision_score(y_true, y_pred))\n",
        "print(\"F1 score:   \", f1_score(y_true, y_pred))"
      ],
      "metadata": {
        "id": "2kEu0_RIhY2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix:\n",
        "#   row: Ground truth\n",
        "#   column: predict\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "USdY8pNyUVCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=[\"No\", \"Yes\"]\n",
        ")\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WOZ-w-9-US8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "xwNpLF4TzNF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred_raw: 0~1\n",
        "fp_rate, tp_rate, threshold = roc_curve(\n",
        "    y_true, y_pred_raw\n",
        ")\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'FPR': fp_rate,\n",
        "    'TPR': tp_rate,\n",
        "    'Threshold': threshold\n",
        "})\n",
        "df['TPR - FPR'] = df['TPR'] - df['FPR']\n",
        "df"
      ],
      "metadata": {
        "id": "lmPEQlTOUWlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC score\n",
        "auc_score = auc(fp_rate, tp_rate)\n",
        "print(f'AUC: {auc_score:.4f}')"
      ],
      "metadata": {
        "id": "O7jm2_IqUjec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve\n",
        "plt.xlabel('False Positive Rate (FPR) 1-Specificity')\n",
        "plt.ylabel('True Positive Rate (TPR) Sensitivity')\n",
        "plt.plot(fp_rate, tp_rate, marker=\"^\")\n",
        "plt.title(f'ROC curve, AUC:{auc_score:.3f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hPML5ZGIUm1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Youden index\n",
        "# https://en.wikipedia.org/wiki/Youden%27s_J_statistic\n",
        "idx = np.argmax(tp_rate - fp_rate)\n",
        "print(f'Youden index: {threshold[idx]:.4f}')"
      ],
      "metadata": {
        "id": "DnKzN4Qahmq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lGmNxfGfKheB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}